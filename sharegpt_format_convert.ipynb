{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qNU9xlvrL90e"},"outputs":[],"source":["import pickle\n","!pip install langchain\n","import langchain"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b_zkwucQ37n","executionInfo":{"status":"ok","timestamp":1701399013021,"user_tz":360,"elapsed":914,"user":{"displayName":"Allen Niemerg","userId":"05361534815983336531"}},"outputId":"dda4981a-c064-421d-85fe-a7658ff39f1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Turn data into ShareGPT format following Allan's synthetic data generation pipeline/process\n"],"metadata":{"id":"ex7VLCnS0bLE"}},{"cell_type":"code","source":["#opening the folder and double checking that is is a list\n","with open('/content/drive/MyDrive/syntheticconvos/synthetic_agent_conversations-2fdd8.pkl', 'rb') as f:\n","    data = pickle.load(f)"],"metadata":{"id":"BJa6f7dRMo8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(data)"],"metadata":{"id":"zFHXWYMSuV_G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701399051199,"user_tz":360,"elapsed":3,"user":{"displayName":"Allen Niemerg","userId":"05361534815983336531"}},"outputId":"ef4d7eaf-562a-491a-e2aa-5d4681b06df3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#Generate log of conversations without LangChain tags before turning into ShareGPT format\n","data = data[0]\n","\n","convo_logs = []\n","for convo_idx in range(len(data)):#len(data)\n","  convo = data[convo_idx][\"conversation\"]\n","  convo_log = []\n","  for message in convo:\n","    convo_log.append(message.content)\n","  convo_log.insert(1, \"Understood. I will act as the specified agent.\")\n","  convo_logs.append(convo_log)"],"metadata":{"id":"qBjM76uVznjO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Optional cell to run to check that step 1 was good\n","for i in convo_logs:\n","  print(i)\n","  print(\"########################################################\")\n","\n"],"metadata":{"id":"Zlg-3Hlg0nML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Turn into ShareGPT format\n","sharegpt_list = []\n","\n","for convo in convo_logs:\n","  sharegpt_dict = dict()\n","  log = []\n","  for message_idx in range(len(convo)):\n","    message = convo[message_idx]\n","    from_and_value = dict()\n","    if message_idx % 2 == 0:\n","      from_and_value[\"from\"] = \"human\"\n","    else:\n","      from_and_value[\"from\"] = \"gpt\"\n","    from_and_value[\"value\"] = message\n","    log.append(from_and_value)\n","  sharegpt_dict[\"conversation\"] = log\n","  sharegpt_list.append(sharegpt_dict)\n","\n","sharegpt_list\n"],"metadata":{"id":"jerbH5ej0oRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the contents of our list of conversations\n","for a in sharegpt_list:\n","  for i in a:\n","      for j in a[i]:\n","          for k in j:\n","            print(type(k), type(j[k]))"],"metadata":{"id":"KRGKKxqE7B88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#writing the file\n","import json\n","type1 = type(\"str\")\n","file_path = 'save_path.jsonl'\n","with open(file_path, 'w') as file:\n","    for entry in sharegpt_list:\n","        json.dump(entry, file)\n","        file.write('\\n')"],"metadata":{"id":"JFJrnII38ys-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-QsfyJba87UC"},"execution_count":null,"outputs":[]}]}
